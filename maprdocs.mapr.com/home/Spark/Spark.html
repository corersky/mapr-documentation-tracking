Spark

   Apache Spark is an open-source processing engine that you can use to
   process Hadoop data. The following diagram shows the components
   involved in running Spark jobs. The following diagram shows the
   components involved in running Spark jobs. See [1]Spark Cluster Mode
   Overview for further details on the different components.

   [SparkArchitecture.png]
   MapR supports the following three types of cluster managers:
     * Spark's own standalone cluster manager
     * YARN
     * Apache Mesos

   Note: Spark on Mesos is available starting in the Spark 2.1.0-1707
   release.
   The configuration and operational steps for Spark differ based on the
   Spark mode you choose to install. The steps to integrate Spark with
   other components are the same when using Standalone and YARN cluster
   mode, except where otherwise noted.

   This section provides documentation about configuring and using Spark
   with MapR, but it does not duplicate the [2]Apache Spark documentation.

   You can also refer to additional documentation available on the [3]MapR
   Converge Community website.

References

   1. https://spark.apache.org/docs/latest/cluster-overview.html
   2. https://spark.apache.org/docs/latest/
   3. https://community.mapr.com/community/products/spark
