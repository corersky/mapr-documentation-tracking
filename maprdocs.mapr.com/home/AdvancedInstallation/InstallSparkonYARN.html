Installing Spark on YARN

   This topic includes instructions for using package managers to download
   and install Spark on YARN from the MEP repository.
   For instructions on setting up the MEP repository, see [1]Step 10:
   Install Ecosystem Components Manually.

   Spark is distributed as three separate packages:
   Package Description
   mapr-spark Install this package on each node where you want to install
   Spark. This package is dependent on the mapr-client package.
   mapr-spark-historyserver Install this optional package on Spark History
   Server nodes. This package is dependent on the mapr-spark and mapr-core
   packages.
   mapr-spark-thriftserver

   Install this optional package on Spark Thrift Server nodes. This
   package is available starting in the MEP 4.0 release. It is dependent
   on the mapr‍-‍spark and mapr‍-‍core packages.

   To install Spark on YARN (Hadoop 2), execute the following commands as
   root or using sudo:
    1. Verify that JDK 1.7 or later is installed on the node where you
       want to install Spark.
    2. Create the /apps/spark directory on MapR-FS, and set the correct
       permissions on the directory:
hadoop fs -mkdir /apps/spark
hadoop fs -chmod 777 /apps/spark
    3. Install the packages:

        On Ubuntu

apt-get install mapr-spark mapr-spark-historyserver mapr-spark-thriftserver

        On RedHat / CentOS

yum install mapr-spark mapr-spark-historyserver mapr-spark-thriftserver

        On SUSE

zypper install mapr-spark mapr-spark-historyserver mapr-spark-thriftserver

       Note: The mapr-spark-historyserver and mapr-spark-thriftserver
       packages are optional.
    4. If you want to integrate Spark with MapR-ES, install the Streams
       Client on each Spark node:
          + On Ubuntu:
 apt-get install mapr-kafka
          + On RedHat/CentOS:
yum install mapr-kafka
    5. If you want to use a Streaming Producer, add the
       spark-streaming-kafka-producer_2.11.jar from the MapR Maven
       repository to the Spark classpath
       (/opt/mapr/spark/spar-<versions>/jars/).
    6. After installing Spark on YARN and before running your Spark jobs,
       follow the steps outlined at [2]Configuring Spark on YARN.

References

   1. file://localhost/root/docsync/tmp/maprdocs.mapr.com/home/AdvancedInstallation/InstallingEcoWithoutInstaller.html#concept_gtv_mp4_2w
   2. file://localhost/root/docsync/tmp/maprdocs.mapr.com/home/Spark/ConfigureSparkOnYarn.html#concept_jwp_3nk_w5
