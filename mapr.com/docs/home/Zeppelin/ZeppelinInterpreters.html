Understanding Zeppelin Interpreters

   Apache Zeppelin interpreters enable you to access specific languages
   and data processing backends. This section describes the interpreters
   you can use with MapR and the use cases they serve.

Supported Zeppelin Interpreters

   Apache Zeppelin on MapR supports the following interpreters:

   Shell
          With the Shell interpreter, you can invoke system shell
          commands. If you have a MapR Filesystem mount point, you can
          access MapR Filesystem using shell commands like ls and cat by
          using the [1]FUSE-Based POSIX Client. See [2]Running Shell
          Commands in Zeppelin for examples that use this interpreter.

   Pig
          The Apache Pig interpreter enables you to run Apache Pig scripts
          and queries. See [3]Running Pig Scripts in Zeppelin for examples
          that use this interpreter.

   JDBC - Drill and Hive
          Apache Zeppelin on MapR provides preconfigured Apache Drill and
          Apache Hive JDBC interpreters. See [4]Running Drill Queries in
          Zeppelin and [5]Running Hive Queries in Zeppelin for examples
          that use these interpreters.

   Livy
          The Apache Livy interpreter is a RESTful interface for
          interacting with Apache Spark. With this interpreter, you can
          run interactive Scala, Python, and R shells, and submit Spark
          jobs.

          The Spark jobs run in YARN cluster mode so they run inside an
          application master process managed by YARN. This has the
          following implications:

          + Allows you to close your Zeppelin notebook without killing
            your Spark jobs.
          + Supports Spark Dynamic Resource Allocation, which allows you
            to set idle timeouts in your Spark context to recapture
            wayward memory.

          Starting in the 1.3 release, MapR Data Science Refinery uses a
          shared Livy session to run all Spark variations. In prior
          releases, it uses separate Livy sessions for Spark, PySpark, and
          SparkR jobs.

          The Livy interpreter does not support [6]ZeppelinContext and
          [7]AngularBind. See the description of the [8]Spark interpreter
          for details about these features.

          Although MapR Data Science Refinery includes Livy, you cannot
          run the Livy UI inside your Zeppelin container.

          The following topics contain examples that use the Livy
          interpreter to access different backend engines:

          + [9]Running Spark Jobs in Zeppelin
          + [10]Accessing MapR Database in Zeppelin Using the MapR
            Database Binary Connector
          + [11]Accessing MapR Event Store For Apache Kafka in Zeppelin
            Using the Livy Interpreter
            Note: See [12]MapR Data Science Refinery Support by MapR Core
            Version for limitations in version support when accessing MapR
            Event Store.

   Spark
          The Apache Spark interpreter is available starting in MapR Data
          Science Refinery 1.1. It provides an alternative to the Livy
          interpreter.

          The Spark interpreter supports the following features not
          supported by the Livy interpreter:

          + [13]ZeppelinContext - Allows you to create dynamic forms and
            share objects between Spark Scala and PySpark code
          + [14]AngularBind - Allows you to display charts using data
            returned from Spark and to pass variables from the Spark
            interpreter to the Angular interpreter

          Starting in MapR Data Science Refinery 1.3, Spark jobs run in
          YARN cluster mode. In prior releases, they run in YARN client
          mode. Running in YARN cluster mode avoids heavy resource
          consumption on your container host machine because the Spark
          driver process does not run on the container host. It also
          provides the advantages noted earlier for the [15]Livy
          interpreter.

          The following topics contain examples that use the Spark
          interpreter to access different backend engines:

          + [16]Running Spark Jobs in Zeppelin
          + [17]Accessing MapR Database in Zeppelin Using the MapR
            Database Binary Connector
          + [18]Accessing MapR Database in Zeppelin Using the MapR
            Database OJAI Connector
          + [19]Accessing MapR Event Store For Apache Kafka in Zeppelin
            Using the Spark Interpreter
            Note: See [20]MapR Data Science Refinery Support by MapR Core
            Version for limitations in version support when accessing MapR
            Event Store.

   MapR Database Shell
          The MapR Database Shell interpreter allows you to run commands
          available in [21]MapR Database Shell (JSON Tables) in the
          Zeppelin UI. Using dbshell commands, you can access MapR
          Database JSON tables without having to write Spark code. The
          interpreter supports all dbshell commands except find commands
          that specify an ordering.

          The interpreter is available starting in MapR Data Science
          Refinery 1.2. You do not have to run any new additional
          configuration steps to use this interpreter.

          Specify the following in the Zeppelin UI to invoke the
          interpreter:

%maprdb

          See [22]Running MapR Database Shell Commands in Zeppelin for
          examples that use this interpreter.

   Livy vs Spark Interpreters

   Starting in MapR Data Science Refinery 1.3, since both the Livy and
   Spark interpreters run in YARN cluster mode, the primary reason for
   choosing the Spark interpreter over the Livy interpreter is support for
   visualization features in the former.
   Note: Neither interpreter supports Spark standalone mode.

Zeppelin Interpreter Use Cases

   The table below summarizes which interpreters to use to access
   different backend engines for different data processing goals:
   Data Processing Goal Zeppelin Interpreter Backend Engine
   Data discovery, exploratory querying Livy, Spark Spark SQL
   JDBC Hive, Drill
   Shell MapR Filesystem
   MapR Database Shell MapR Database JSON
   ETL, preparation Livy, Spark Spark, PySpark, SparkSQL, SparkStreaming,
   Livy, Spark MapR Database (through the [23]MapR Database Connectors for
   Apache Spark)
   Livy, Spark MapR Event Store For Apache Kafka (through [24]Spark jobs
   that query MapR Event Store For Apache Kafka)
   Note: See [25]MapR Data Science Refinery Support by MapR Core Version
   for limitations in version support when accessing MapR Event Store.
   JDBC Hive
   Pig MapReduce
   Machine and deep learning, data science Livy, Spark SparkML
   Reporting, visualization JDBC Hive, Drill

   The following are general guidelines for choosing between the Livy and
   Spark interpreters:
     * Use Livy for jobs that are long running or resource intensive
     * Use Spark if you use visualization features that Livy does not
       support

Unsupported Zeppelin Interpreters

   Apache Zeppelin on MapR does not support the HBase interpreter. To
   access MapR Database binary tables, use the [26]MapR Database Binary
   Connector for Apache Spark with either the Livy or Spark interpreter.

Sequential Execution of Notebook Paragraphs

   Starting in the 1.3 release, MapR Data Science Refinery runs paragraphs
   in a notebook sequentially rather than in parallel. This allows
   paragraphs to run properly when they have dependencies on earlier
   paragraphs in the same notebook.

References

   1. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinDockerRunParameters.html#concept_rhn_gb2_rbb__section_i4r_5c2_rbb
   2. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinShell.html#task_y2t_g5c_rbb
   3. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinPig.html#ZeppelinPig
   4. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinDrill.html#concept_msx_yzh_qbb
   5. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinHive.html#concept_nlc_lb3_qbb
   6. https://zeppelin.apache.org/docs/latest/interpreter/spark.html#zeppelincontext
   7. https://zeppelin.apache.org/docs/latest/displaysystem/back-end-angular.html
   8. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinInterpreters.html#concept_q41_m2r_4bb__dlentry_cv4_s55_52b
   9. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinSpark.html#ZeppelinSpark
  10. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinMapRDB.html#ZeppelinMapRDB
  11. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinMapRES.html#concept_kv3_ws3_qbb
  12. file://localhost/root/docsync/tmp/mapr.com/docs/home/DataScienceRefinery/DSRSupportByCoreVersion.html
  13. https://zeppelin.apache.org/docs/latest/interpreter/spark.html#zeppelincontext
  14. https://zeppelin.apache.org/docs/latest/displaysystem/back-end-angular.html
  15. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinInterpreters.html#concept_q41_m2r_4bb__dlentry_pfl_wlk_v2b
  16. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinSpark.html#ZeppelinSpark
  17. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinMapRDB.html#ZeppelinMapRDB
  18. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinMapRDBOJAI.html#ZeppelinMapRDB
  19. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinMapRESSpark.html#concept_kv3_ws3_qbb
  20. file://localhost/root/docsync/tmp/mapr.com/docs/home/DataScienceRefinery/DSRSupportByCoreVersion.html
  21. file://localhost/root/docsync/tmp/mapr.com/docs/home/ReferenceGuide/mapr_dbshell.html#mapr_dbshell
  22. file://localhost/root/docsync/tmp/mapr.com/docs/home/Zeppelin/ZeppelinMapRDBShell.html#ZeppelinMapRDBShell
  23. file://localhost/root/docsync/tmp/mapr.com/docs/home/Spark/SparkConnectorsMapRDB.html#concept_ygh_ywm_gz
  24. file://localhost/root/docsync/tmp/mapr.com/docs/home/Spark/Spark_IntegrateMapRStreams_Consume.html#task_mm5_b5j_w5
  25. file://localhost/root/docsync/tmp/mapr.com/docs/home/DataScienceRefinery/DSRSupportByCoreVersion.html
  26. file://localhost/root/docsync/tmp/mapr.com/docs/home/Spark/SparkHBaseConnector.html#concept_gth_txm_gz
